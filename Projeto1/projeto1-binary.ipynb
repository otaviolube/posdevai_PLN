{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento de Linguagem Natural\n",
    "\n",
    "**Prof. Dr. Hilário Thomaz Alves de Oliveira**  \n",
    "**Pós-graduação em Desenvolvimento de Aplicações Inteligentes**  \n",
    "**Processamento de Linguagem Natural — Projeto 01 - Classificação de Decisões Judiciais**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome:** Otávio Lube dos Santos  \n",
    "**Matrícula:** 20231DEVAI0157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('joelniklaus/brazilian_court_decisions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['process_number', 'orgao_julgador', 'publish_date', 'judge_relator', 'ementa_text', 'decision_description', 'judgment_text', 'judgment_label', 'unanimity_text', 'unanimity_label'],\n",
       "        num_rows: 3234\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['process_number', 'orgao_julgador', 'publish_date', 'judge_relator', 'ementa_text', 'decision_description', 'judgment_text', 'judgment_label', 'unanimity_text', 'unanimity_label'],\n",
       "        num_rows: 404\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['process_number', 'orgao_julgador', 'publish_date', 'judge_relator', 'ementa_text', 'decision_description', 'judgment_text', 'judgment_label', 'unanimity_text', 'unanimity_label'],\n",
       "        num_rows: 405\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'process_number': '0800304-08.2018.8.02.0000',\n",
       " 'orgao_julgador': 'Tribunal Pleno',\n",
       " 'publish_date': '12/03/2019',\n",
       " 'judge_relator': 'Des. João Luiz Azevedo Lessa',\n",
       " 'ementa_text': 'DIREITO PENAL E PROCESSUAL PENAL. REVISÃO CRIMINAL. ART. 621 DO CÓDIGO DE PROCESSO PENAL. REQUERENTE CONDENADO EM JÚRI POPULAR PELA PRÁTICA DOS CRIMES DE HOMICÍDIO DUPLAMENTE QUALIFICADO E HOMICÍDIO QUALIFICADO TENTADO. PLEITO DE REFAZIMENTO DA DOSIMETRIA DA PENA IMPOSTA AO REQUERENTE. ADMISSIBILIDADE NA VIA REVISIONAL. PRECEDENTES. ALEGAÇÃO DE ERRO NO PROCESSO DE DOSIMETRIA DA PENA. COMPORTAMENTO DA VÍTIMA. CIRCUNSTÂNCIA JUDICIAL NEUTRA QUE NÃO PODE SER CONSIDERADA DE FORMA DESFAVORÁVEL AO SENTENCIANDO SEGUNDO PRECEDENTES DO SUPERIOR TRIBUNAL DE JUSTIÇA E NOVO ENTENDIMENTO DA CÂMARA CRIMINAL DESTE TRIBUNAL DE JUSTIÇA. AFASTAMENTO. CULPABILIDADE. AUSÊNCIA DE EXPOSIÇÃO DE MOTIVOS PARA O INCREMENTO DA PENA-BASE. AFASTADO O DESVALOR. VALORAÇÃO ATRIBUÍDA ÀS CIRCUNSTÂNCIAS DO CRIME MANTIDA. FUNDAMENTAÇÃO IDÔNEA. PENA-BASE REDUZIDA. COMPENSAÇÃO ENTRE A AGRAVANTE DA MOTIVAÇÃO TORPE E A ATENUANTE DA CONFISSÃO ESPONTÂNEA. PENA PRIVATIVA DE LIBERDADE REDIMENSIONADA. CRIME TENTADO. APLICADA A FRAÇÃO REDUTORA MÁXIMA ANTE A DISTÂNCIA ENTRE OS ATOS PRATICADOS PELO REQUERENTE E A CONSUMAÇÃO DO CRIME. PENA REDIMENSIONADA. REVISÃO CRIMINAL JULGADA PARCIALMENTE PROCEDENTE. DECISÃO UNÂNIME.',\n",
       " 'decision_description': 'DIREITO PENAL E PROCESSUAL PENAL. REVISÃO CRIMINAL. ARTIGO 621 DO CÓDIGO DE PROCESSO PENAL. REQUERENTE CONDENADO EM JÚRI POPULAR PELA PRÁTICA DOS CRIMES DE HOMICÍDIO DUPLAMENTE QUALIFICADO E HOMICÍDIO QUALIFICADO TENTADO. PLEITO DE REFAZIMENTO DA DOSIMETRIA DA PENA IMPOSTA AO REQUERENTE. ADMISSIBILIDADE NA VIA REVISIONAL. PRECEDENTES. ALEGAÇÃO DE ERRO NO PROCESSO DE DOSIMETRIA DA PENA. COMPORTAMENTO DA VÍTIMA. CIRCUNSTÂNCIA JUDICIAL NEUTRA QUE NÃO PODE SER CONSIDERADA DE FORMA DESFAVORÁVEL AO SENTENCIANDO SEGUNDO PRECEDENTES DO SUPERIOR TRIBUNAL DE JUSTIÇA E NOVO ENTENDIMENTO DA CÂMARA CRIMINAL DESTE TRIBUNAL DE JUSTIÇA. AFASTAMENTO. CULPABILIDADE. AUSÊNCIA DE EXPOSIÇÃO DE MOTIVOS PARA O INCREMENTO DA PENA-BASE. AFASTADO O DESVALOR. VALORAÇÃO ATRIBUÍDA ÀS CIRCUNSTÂNCIAS DO CRIME MANTIDA. FUNDAMENTAÇÃO IDÔNEA. PENA-BASE REDUZIDA. COMPENSAÇÃO ENTRE A AGRAVANTE DA MOTIVAÇÃO TORPE E A ATENUANTE DA CONFISSÃO ESPONTÂNEA. PENA PRIVATIVA DE LIBERDADE REDIMENSIONADA. CRIME TENTADO. APLICADA A FRAÇÃO REDUTORA MÁXIMA ANTE A DISTÂNCIA ENTRE OS ATOS PRATICADOS PELO REQUERENTE E A CONSUMAÇÃO DO CRIME. PENA REDIMENSIONADA.',\n",
       " 'judgment_text': ' REVISÃO CRIMINAL JULGADA PARCIALMENTE PROCEDENTE',\n",
       " 'judgment_label': 'partial',\n",
       " 'unanimity_text': ' DECISÃO UNÂNIME',\n",
       " 'unanimity_label': 'unanimity'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size: 3234 -- 3234\n",
      "Test size: 405 -- 405\n"
     ]
    }
   ],
   "source": [
    "train_texts = dataset['train']['decision_description']\n",
    "train_labels = dataset['train']['judgment_label']\n",
    "\n",
    "test_texts = dataset['test']['decision_description']\n",
    "test_labels = dataset['test']['judgment_label']\n",
    "\n",
    "print(f'\\nTrain size: {len(train_texts)} -- {len(train_labels)}')\n",
    "print(f'Test size: {len(test_texts)} -- {len(test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Labels Distribution: Counter({'no': 1960, 'partial': 677, 'yes': 597})\n",
      "Test Labels Distribution: Counter({'no': 234, 'partial': 93, 'yes': 78})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(f'Train Labels Distribution: {Counter(train_labels)}')\n",
    "print(f'Test Labels Distribution: {Counter(test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Labels Distribution: Counter({np.int64(0): 1960, np.int64(1): 677, np.int64(2): 597})\n",
      "Test Labels Distribution: Counter({np.int64(0): 234, np.int64(1): 93, np.int64(2): 78})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(train_labels)\n",
    "\n",
    "train_labels = label_encoder.transform(train_labels)\n",
    "test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "print(f'Train Labels Distribution: {Counter(train_labels)}')\n",
    "print(f'Test Labels Distribution: {Counter(test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_texts(list_texts):\n",
    "  nlp = spacy.load('pt_core_news_sm', disable=['ner'])\n",
    "  new_texts = []\n",
    "  with tqdm(total=len(list_texts), desc='Preprocessing') as pbar:\n",
    "    for text in list_texts:\n",
    "      doc = nlp(text)\n",
    "      tokens = [t.lemma_.lower() for t in doc if t.pos_ != 'PUNCT' and not t.is_stop]\n",
    "      texto_normalizado = ' '.join(tokens)\n",
    "      new_texts.append(texto_normalizado)\n",
    "      pbar.update(1)\n",
    "  return new_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 3234/3234 [00:18<00:00, 177.10it/s]\n"
     ]
    }
   ],
   "source": [
    "train_texts = preprocess_texts(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 405/405 [00:02<00:00, 169.37it/s]\n"
     ]
    }
   ],
   "source": [
    "test_texts = preprocess_texts(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer Option: binary\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer_option = 'binary'\n",
    "\n",
    "vectorizer = None\n",
    "\n",
    "if vectorizer_option == 'binary':\n",
    "    vectorizer = CountVectorizer(binary=True, max_features=None, ngram_range=(1, 1))\n",
    "elif vectorizer_option == 'count':\n",
    "    vectorizer = CountVectorizer(binary=False, max_features=None, ngram_range=(1, 1))\n",
    "elif vectorizer_option == 'tf_idf':\n",
    "    vectorizer = TfidfVectorizer(max_features=None, ngram_range=(1, 1))\n",
    "\n",
    "print(f'Vectorizer Option: {vectorizer_option}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Raw Text: direito penal processual penal revisão criminal artigo 621 código processo penal requerente condenado júri popular prática crimes homicídio duplamente qualificado homicídio qualificado tentado pleito refazimento dosimetria pena imposta requerente admissibilidade via revisional precedentes alegação erro processo dosimetria pena comportamento vítima circunstância judicial neutra considerada desfavorável sentenciando precedentes superior tribunal justiça entendimento câmara criminal tribunal justiça afastamento culpabilidade ausência exposição motivos incremento pena-base afastado desvalor valoração atribuída circunstâncias crime mantida fundamentação idônea pena-base reduzida compensação agravante motivação torpe atenuante confissão espontânea pena privativa liberdade redimensionada crime tentado aplicada fração redutora máxima ante distância atos praticados requerente consumação crime pena redimensionada\n",
      "\n",
      "Example Vectorized Text: [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(train_texts).toarray()\n",
    "X_test = vectorizer.transform(test_texts).toarray()\n",
    "\n",
    "print(f'\\nExample Raw Text: {train_texts[0]}')\n",
    "print(f'\\nExample Vectorized Text: {X_train[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 12453\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocabulary: {len(vectorizer.vocabulary_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=500),\n",
    "    'Multinomial NB': MultinomialNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Quadratic Discriminant': QuadraticDiscriminantAnalysis(),\n",
    "    'Passive Aggressive': PassiveAggressiveClassifier(),\n",
    "    'MLP Classifier': MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       234\n",
      "           1       0.65      0.67      0.66        93\n",
      "           2       0.62      0.56      0.59        78\n",
      "\n",
      "    accuracy                           0.74       405\n",
      "   macro avg       0.69      0.69      0.69       405\n",
      "weighted avg       0.74      0.74      0.74       405\n",
      "\n",
      "\n",
      "Classifier: Multinomial NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71       234\n",
      "           1       0.47      0.61      0.53        93\n",
      "           2       0.48      0.56      0.52        78\n",
      "\n",
      "    accuracy                           0.62       405\n",
      "   macro avg       0.58      0.61      0.59       405\n",
      "weighted avg       0.65      0.62      0.63       405\n",
      "\n",
      "\n",
      "Classifier: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78       234\n",
      "           1       0.74      0.34      0.47        93\n",
      "           2       0.51      0.40      0.45        78\n",
      "\n",
      "    accuracy                           0.67       405\n",
      "   macro avg       0.65      0.54      0.57       405\n",
      "weighted avg       0.67      0.67      0.65       405\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.95      0.82       234\n",
      "           1       0.78      0.46      0.58        93\n",
      "           2       0.79      0.38      0.52        78\n",
      "\n",
      "    accuracy                           0.73       405\n",
      "   macro avg       0.76      0.60      0.64       405\n",
      "weighted avg       0.74      0.73      0.71       405\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82       234\n",
      "           1       0.84      0.44      0.58        93\n",
      "           2       0.81      0.38      0.52        78\n",
      "\n",
      "    accuracy                           0.73       405\n",
      "   macro avg       0.79      0.60      0.64       405\n",
      "weighted avg       0.76      0.73      0.71       405\n",
      "\n",
      "\n",
      "Classifier: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       234\n",
      "           1       0.72      0.59      0.65        93\n",
      "           2       0.70      0.54      0.61        78\n",
      "\n",
      "    accuracy                           0.77       405\n",
      "   macro avg       0.74      0.68      0.70       405\n",
      "weighted avg       0.76      0.77      0.76       405\n",
      "\n",
      "\n",
      "Classifier: Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76       234\n",
      "           1       0.54      0.51      0.52        93\n",
      "           2       0.55      0.51      0.53        78\n",
      "\n",
      "    accuracy                           0.67       405\n",
      "   macro avg       0.61      0.60      0.61       405\n",
      "weighted avg       0.66      0.67      0.66       405\n",
      "\n",
      "\n",
      "Classifier: Quadratic Discriminant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/otaviolube/Desktop/pos-devai-ifes/6-proc-lig-nat/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 2 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.10      0.18       234\n",
      "           1       0.26      0.40      0.32        93\n",
      "           2       0.21      0.65      0.32        78\n",
      "\n",
      "    accuracy                           0.27       405\n",
      "   macro avg       0.45      0.38      0.27       405\n",
      "weighted avg       0.61      0.27      0.24       405\n",
      "\n",
      "\n",
      "Classifier: Passive Aggressive\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       234\n",
      "           1       0.66      0.66      0.66        93\n",
      "           2       0.60      0.49      0.54        78\n",
      "\n",
      "    accuracy                           0.73       405\n",
      "   macro avg       0.68      0.66      0.67       405\n",
      "weighted avg       0.72      0.73      0.72       405\n",
      "\n",
      "\n",
      "Classifier: MLP Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       234\n",
      "           1       0.68      0.66      0.67        93\n",
      "           2       0.57      0.42      0.49        78\n",
      "\n",
      "    accuracy                           0.73       405\n",
      "   macro avg       0.68      0.65      0.66       405\n",
      "weighted avg       0.72      0.73      0.72       405\n",
      "\n",
      "            Classificador    Acurácia    Precisão      Recall    F1-Score\n",
      "0     Logistic Regression      74.074      73.862      74.074      73.936\n",
      "1          Multinomial NB      62.222      65.468      62.222      63.162\n",
      "2                     KNN      67.160      66.994      67.160      64.539\n",
      "3                     SVM      73.086      74.454      73.086      70.501\n",
      "4           Random Forest      73.333      75.763      73.333      70.534\n",
      "5                 XGBoost  **76.543**  **75.849**  **76.543**  **75.602**\n",
      "6           Decision Tree      66.667      66.115      66.667      66.343\n",
      "7  Quadratic Discriminant      27.407      61.290      27.407      23.712\n",
      "8      Passive Aggressive      72.840      72.158      72.840      72.335\n",
      "9          MLP Classifier      73.333      72.159      73.333      72.431\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Classificador', 'Acurácia', 'Precisão', 'Recall', 'F1-Score'])\n",
    "\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    print(f'\\nClassifier: {classifier_name}')\n",
    "\n",
    "    classifier.fit(X_train, train_labels)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    report = classification_report(test_labels, y_pred, output_dict=True, digits=5)\n",
    "\n",
    "    print(classification_report(test_labels, y_pred))\n",
    "\n",
    "    # ConfusionMatrixDisplay.from_estimator(classifier, X_test, test_labels, display_labels=['Negative', 'Positive']).plot()\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(test_labels, y_pred, average='weighted')\n",
    "\n",
    "    results_df.loc[len(results_df)] = {\n",
    "        'Classificador': classifier_name,\n",
    "        'Acurácia': accuracy,\n",
    "        'Precisão': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "best_accuracy = results_df.loc[results_df['Acurácia'].idxmax(), 'Classificador']\n",
    "results_df['Acurácia'] = results_df.apply(lambda x: f'**{x[\"Acurácia\"] * 100:.3f}**' if x['Classificador'] == best_accuracy else f'{x[\"Acurácia\"] * 100:.3f}', axis=1)\n",
    "\n",
    "best_precision = results_df.loc[results_df['Precisão'].idxmax(), 'Classificador']\n",
    "results_df['Precisão'] = results_df.apply(lambda x: f'**{x[\"Precisão\"] * 100:.3f}**' if x['Classificador'] == best_precision else f'{x[\"Precisão\"] * 100:.3f}', axis=1)\n",
    "\n",
    "best_recall = results_df.loc[results_df['Recall'].idxmax(), 'Classificador']\n",
    "results_df['Recall'] = results_df.apply(lambda x: f'**{x[\"Recall\"] * 100:.3f}**' if x['Classificador'] == best_recall else f'{x[\"Recall\"] * 100:.3f}', axis=1)\n",
    "\n",
    "best_f1 = results_df.loc[results_df['F1-Score'].idxmax(), 'Classificador']\n",
    "results_df['F1-Score'] = results_df.apply(lambda x: f'**{x[\"F1-Score\"] * 100:.3f}**' if x['Classificador'] == best_f1 else f'{x[\"F1-Score\"] * 100:.3f}', axis=1)\n",
    "\n",
    "results_df.to_excel(f'resultados_classificadores_{vectorizer_option}.xlsx', index=False)\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_excel(f'resultados_classificadores_binary.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
